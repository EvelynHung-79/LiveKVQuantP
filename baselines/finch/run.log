[2026-02-11 11:00:06,990][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-11 11:00:06,990][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-11 11:00:06,990][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-11 11:00:07,981][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:00:08,192][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-11 11:00:08,542][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:00:08,930][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-11 11:00:09,221][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:00:09,519][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-11 11:00:09,893][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:00:10,114][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-11 11:00:10,392][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:00:10,604][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-11 11:00:11,307][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:00:11,530][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-11 11:00:11,554][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-11 11:00:11,555][__main__][INFO] - Model config check - torch_dtype: Not Found
[2026-02-11 11:00:11,555][__main__][INFO] - Model config check - device_map: Not Found
[2026-02-11 11:00:12,065][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:00:12,288][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-11 11:03:54,500][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-11 11:03:54,500][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-11 11:03:54,500][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-11 11:03:55,309][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:03:55,560][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-11 11:03:55,797][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:03:56,013][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-11 11:03:56,306][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:03:56,561][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-11 11:03:56,824][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:03:57,076][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-11 11:03:57,367][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:03:57,589][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-11 11:03:58,323][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:03:58,532][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-11 11:03:58,558][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-11 11:03:58,558][__main__][INFO] - Model config check - torch_dtype: bfloat16
[2026-02-11 11:03:58,558][__main__][INFO] - Model config check - device_map: auto
[2026-02-11 11:03:59,242][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:03:59,456][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-11 11:07:02,394][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-11 11:07:02,394][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-11 11:07:02,394][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-11 11:07:03,179][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:07:03,398][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-11 11:07:03,685][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:07:04,054][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-11 11:07:04,399][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:07:04,620][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-11 11:07:04,903][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:07:05,151][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-11 11:07:05,369][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:07:05,749][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-11 11:07:06,875][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:07:07,140][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-11 11:07:07,159][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-11 11:07:07,160][__main__][INFO] - Model config check - torch_dtype: bfloat16
[2026-02-11 11:07:07,160][__main__][INFO] - Model config check - device_map: auto
[2026-02-11 11:07:07,724][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-11 11:07:07,987][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-11 11:07:08,792][accelerate.utils.modeling][INFO] - Device 0 seems unavailable, Proceeding to check subsequent devices.
[2026-02-11 11:20:08,449][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-11 11:20:08,450][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-11 11:20:08,451][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-11 11:20:13,696][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-11 11:20:13,702][__main__][INFO] - Model config check - torch_dtype: bfloat16
[2026-02-11 11:20:13,703][__main__][INFO] - Model config check - device_map: auto
[2026-02-11 11:20:16,619][accelerate.utils.modeling][INFO] - Device 0 seems unavailable, Proceeding to check subsequent devices.
[2026-02-11 11:26:40,552][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-11 11:26:49,049][accelerate.utils.modeling][INFO] - Device 0 seems unavailable, Proceeding to check subsequent devices.
[2026-02-11 11:27:42,056][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-11 11:27:55,368][accelerate.utils.modeling][INFO] - Device 0 seems unavailable, Proceeding to check subsequent devices.
[2026-02-11 11:42:12,881][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
