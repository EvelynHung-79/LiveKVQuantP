[2026-02-06 20:07:33,626][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:07:33,626][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:07:33,626][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:07:40,292][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:40,498][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:07:40,820][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:41,025][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:07:41,247][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:41,461][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:07:41,662][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:41,865][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:07:42,147][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:42,353][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:07:43,170][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:43,386][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:07:43,409][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:07:46,520][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:46,721][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:07:53,965][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:07:53,965][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:07:53,965][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:07:54,791][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:54,992][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:07:55,203][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:55,429][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:07:55,637][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:55,838][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:07:56,041][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:56,248][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:07:56,444][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:56,647][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:07:57,386][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:57,595][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:07:57,621][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:07:58,129][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:07:58,371][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:08:01,382][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:08:01,382][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:08:01,382][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:08:02,192][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:08:02,397][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:08:02,603][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:08:02,805][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:08:03,009][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:08:03,221][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:08:03,417][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:08:03,626][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:08:03,833][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:08:04,032][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:08:04,722][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:08:04,933][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:08:04,948][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:08:05,463][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:08:05,674][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:23:32,358][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:23:32,364][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:23:32,365][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:23:33,689][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:23:33,893][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:23:34,101][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:23:34,301][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:23:34,505][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:23:34,725][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:23:34,931][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:23:35,140][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:23:35,338][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:23:35,548][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:23:36,528][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:23:36,737][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:23:36,768][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:23:38,589][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:23:38,789][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:25:54,321][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:25:54,526][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:25:54,779][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:25:54,995][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 404 Not Found"
[2026-02-06 20:25:54,996][__main__][INFO] - Instantiating <context_compression.trainers.trainer.Trainer>
[2026-02-06 20:25:58,291][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:25:58,291][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:25:58,291][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:25:59,511][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:25:59,719][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:25:59,918][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:00,138][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:00,343][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:00,555][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:00,753][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:00,956][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:26:01,157][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:01,364][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:26:02,490][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:02,708][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:26:02,743][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:26:03,322][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:03,521][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:08,117][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:08,321][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:08,596][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:08,806][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 404 Not Found"
[2026-02-06 20:26:08,807][__main__][INFO] - Instantiating <context_compression.trainers.trainer.Trainer>
[2026-02-06 20:26:10,834][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:26:10,834][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:26:10,834][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:26:11,681][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:11,884][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:12,104][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:12,310][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:12,518][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:12,722][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:12,925][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:13,128][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:26:13,331][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:13,535][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:26:14,208][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:14,429][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:26:14,447][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:26:14,965][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:15,180][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:18,714][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:18,913][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:26:19,119][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:26:19,338][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 404 Not Found"
[2026-02-06 20:26:19,339][__main__][INFO] - Instantiating <context_compression.trainers.trainer.Trainer>
[2026-02-06 20:35:20,181][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:35:20,181][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:35:20,181][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:35:20,999][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:21,220][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:21,431][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:21,630][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:21,835][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:22,041][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:22,248][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:22,459][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:35:22,655][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:22,862][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:35:23,531][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:23,742][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:35:23,767][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:35:24,260][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:24,471][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:28,062][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:28,281][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:28,489][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:28,709][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 404 Not Found"
[2026-02-06 20:35:28,710][__main__][INFO] - Instantiating <context_compression.trainers.trainer.Trainer>
[2026-02-06 20:35:30,756][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:35:30,756][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:35:30,756][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:35:31,597][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:31,884][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:32,086][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:32,320][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:32,546][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:32,770][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:33,015][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:33,263][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:35:33,498][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:33,769][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:35:34,483][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:34,705][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:35:34,730][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:35:35,427][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:35,650][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:39,279][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:39,498][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:39,709][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:39,918][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 404 Not Found"
[2026-02-06 20:35:39,920][__main__][INFO] - Instantiating <context_compression.trainers.trainer.Trainer>
[2026-02-06 20:35:41,982][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2026-02-06 20:35:41,982][__main__][INFO] - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

[2026-02-06 20:35:41,982][__main__][INFO] - Instantiating <transformers.AutoTokenizer.from_pretrained>
[2026-02-06 20:35:42,770][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:42,978][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:43,190][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:43,433][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:43,671][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:43,916][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:44,123][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:44,351][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2026-02-06 20:35:44,582][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:44,788][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
[2026-02-06 20:35:45,460][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Meta-Llama-3.1-8B-Instruct "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:45,671][httpx][INFO] - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.1-8B-Instruct "HTTP/1.1 200 OK"
[2026-02-06 20:35:45,690][__main__][INFO] - Instantiating <context_compression.models.modeling_llama.LlamaForCompressedCausalLM.from_pretrained>
[2026-02-06 20:35:46,208][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:46,466][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:50,086][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:50,302][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/generation_config.json "HTTP/1.1 200 OK"
[2026-02-06 20:35:50,540][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 307 Temporary Redirect"
[2026-02-06 20:35:50,740][httpx][INFO] - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py "HTTP/1.1 404 Not Found"
[2026-02-06 20:35:50,741][__main__][INFO] - Instantiating <context_compression.trainers.trainer.Trainer>
