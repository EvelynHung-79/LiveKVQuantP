{
    "task": "qasper",
    "version": "v1",
    "args": {
        "input_mode": "longbench",
        "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "bench_version": "v1",
        "task_type": "single-doc",
        "num_samples": 10,
        "output_len": 64,
        "chunk_size": 512,
        "n_warmup": 2,
        "bits": 4,
        "ema_alpha": 0.2,
        "clip_factor_n": 4.0,
        "outlier_ratio": 0.01
    },
    "avg_score": 0.4168036434828122,
    "avg_latency_ms": 3874.468697444536,
    "max_peak_memory_mb": 16478.41943359375,
    "details": [
        {
            "index": 0,
            "score": 0.3846153846153846,
            "metric": "F1",
            "output": "The ground truth for fake news is established by a single person manually labelling tweets as containing fake news or not.",
            "ground_truth": "Ground truth is not established in the paper",
            "peak_memory_mb": 16112.79052734375,
            "latency_ms": 3001.2764970306307
        },
        {
            "index": 1,
            "score": 0.4117647058823529,
            "metric": "F1",
            "output": "An extension of the NetVLAD approach, which adds ghost clusters to map any noisy or irrelevant content into ghost clusters and not included during feature aggregation.",
            "ground_truth": "extension of the NetVLAD, adds Ghost clusters along with the NetVLAD clusters",
            "peak_memory_mb": 15991.35498046875,
            "latency_ms": 3131.135645089671
        },
        {
            "index": 2,
            "score": 0.0,
            "metric": "F1",
            "output": "By 0.18% to 0.18% (68.8% to 71.8%) when applied to the IEMOCAP dataset.",
            "ground_truth": "the attention model, MDREA, also outperforms the best existing research results (WAP 0.690 to 0.688)",
            "peak_memory_mb": 16152.91748046875,
            "latency_ms": 4071.769825182855
        },
        {
            "index": 3,
            "score": 0.25641025641025644,
            "metric": "F1",
            "output": "Context tweets are proposed as additional features, including author information, conversation type, use of the same hashtags or emojis. Additionally, text sequences of context tweets are directly used as an additional feature of neural network models.",
            "ground_truth": "using tweets that one has replied or quoted to as contextual information",
            "peak_memory_mb": 15957.59228515625,
            "latency_ms": 3776.4360250439495
        },
        {
            "index": 4,
            "score": 0.9433962264150945,
            "metric": "F1",
            "output": "They looked at FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.",
            "ground_truth": "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney",
            "peak_memory_mb": 16152.91845703125,
            "latency_ms": 5432.244617026299
        },
        {
            "index": 5,
            "score": 1.0,
            "metric": "F1",
            "output": "yes",
            "ground_truth": "Yes",
            "peak_memory_mb": 16315.10498046875,
            "latency_ms": 2095.465499907732
        },
        {
            "index": 6,
            "score": 0.07407407407407407,
            "metric": "F1",
            "output": "Extrinsic evaluation is proposed for this task, with importance annotations being used to score peer summaries.",
            "ground_truth": "Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2",
            "peak_memory_mb": 16396.69482421875,
            "latency_ms": 3754.2959870770574
        },
        {
            "index": 7,
            "score": 0.6363636363636364,
            "metric": "F1",
            "output": "The CNN/DailyMail, New York Times Annotated Corpus (NYT), and XSum datasets are used for evaluation.",
            "ground_truth": "CNN/DailyMail news highlights, New York Times Annotated Corpus, XSum",
            "peak_memory_mb": 16478.41943359375,
            "latency_ms": 4916.283413069323
        },
        {
            "index": 8,
            "score": 0.41379310344827586,
            "metric": "F1",
            "output": "The proposed GM_KL approach achieves better performance than other approaches on the benchmark word similarity and entailment datasets.",
            "ground_truth": "GM$\\_$KL achieves better correlation than existing approaches for various metrics on SCWS dataset.",
            "peak_memory_mb": 16035.2451171875,
            "latency_ms": 2621.6911720111966
        },
        {
            "index": 9,
            "score": 0.04761904761904761,
            "metric": "F1",
            "output": "The ensemble method works by selecting models, starting with the best performing model according to validation performance, and iteratively adding the best performing model that had not been previously tried, discarding it if it doesn't improve validation performance.",
            "ground_truth": "simply averaging the predictions from the constituent single models",
            "peak_memory_mb": 16315.10400390625,
            "latency_ms": 5944.088293006644
        }
    ]
}